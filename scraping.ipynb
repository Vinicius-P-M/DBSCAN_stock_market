{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1045c289-3d90-4dd3-a200-06a27c58e0f0",
   "metadata": {},
   "source": [
    "## Scraping 'Fundamentus' website for stock information ##\n",
    "\n",
    "'Fundamentus' is a good website for finding financial information on stocks traded in the Brazilian Stock Exchange (B3). The used URL (https://www.fundamentus.com.br/resultado.php) is a table of all the traded stocks along with several indicators. \n",
    "\n",
    "For the purpose of this project, I'll focus on the 50 most traded stocks (average daily volume 2 months).\n",
    "\n",
    "A CSV file is also generated to faciliate the analysis latter on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d49732-f1cb-4e93-880c-dedea2eb465f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#required packages\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dabfe814-e260-4a38-97f1-7d7f0de9ca0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from market...\n",
      "Success! 'top_50_stocks.csv' generated.\n",
      "\n",
      "Preview of the top 5 (sorted by liquidity, but volume is hidden):\n",
      "    Ticker  Liquidity_Ratio  PE_Ratio  Dividend_Yield\n",
      "720  VALE3              124    1082.0           10.59\n",
      "499  PETR4               82     512.0           10.49\n",
      "687  ITUB4                0    1001.0           11.37\n",
      "65   AXIA3              192   -2454.0            7.11\n",
      "618  BBDC4                0     837.0            7.90\n"
     ]
    }
   ],
   "source": [
    "def clean_numeric_column(series):\n",
    "    \"\"\"\n",
    "    Cleans string columns from the website: \n",
    "    Removes dots (thousand sep), replaces commas with dots, and removes '%'.\n",
    "    \"\"\"\n",
    "    return pd.to_numeric(\n",
    "        series.astype(str)\n",
    "              .str.replace('.', '', regex=False)\n",
    "              .str.replace(',', '.', regex=False)\n",
    "              .str.replace('%', '', regex=False),\n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "def scrape_top_50_indicators():\n",
    "    url = \"https://www.fundamentus.com.br/resultado.php\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(\"Fetching data from market...\")\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        \n",
    "        #Reading the HTML table\n",
    "        tables = pd.read_html(io.StringIO(response.text))\n",
    "        df = tables[0]\n",
    "        \n",
    "        #Mapping Portuguese columns to English\n",
    "        columns_map = {\n",
    "            'Papel': 'Ticker',\n",
    "            'P/L': 'PE_Ratio',\n",
    "            'Div.Yield': 'Dividend_Yield',\n",
    "            'Liq. Corr.': 'Liquidity_Ratio',\n",
    "            'Liq.2meses': 'Avg_Daily_Volume_2m'\n",
    "        }\n",
    "        df = df.rename(columns=columns_map)\n",
    "\n",
    "        #list of columns to clean (including the volume for sorting)\n",
    "        numeric_cols = ['PE_Ratio', 'Dividend_Yield', 'Liquidity_Ratio', 'Avg_Daily_Volume_2m']\n",
    "        for col in numeric_cols:\n",
    "            df[col] = clean_numeric_column(df[col])\n",
    "        \n",
    "        #sort by Volume (Highest to Lowest)\n",
    "        df_sorted = df.sort_values(by='Avg_Daily_Volume_2m', ascending=False)\n",
    "        \n",
    "        #Take the TOP 50 most traded companies\n",
    "        df_top_50 = df_sorted.head(50).copy()\n",
    "        \n",
    "        #keeping only final columns\n",
    "        final_df = df_top_50[['Ticker', 'Liquidity_Ratio', 'PE_Ratio', 'Dividend_Yield']]\n",
    "        \n",
    "        #saving to a CSV file\n",
    "        output_file = 'top_50_stocks.csv'\n",
    "        final_df.to_csv(output_file, index=False, sep=',', encoding='utf-8')\n",
    "        \n",
    "        print(f\"Success! '{output_file}' generated.\")\n",
    "        print(\"\\nPreview of the top 5 (sorted by liquidity, but volume is hidden):\")\n",
    "        print(final_df.head())\n",
    "        \n",
    "        return final_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_top_50_indicators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f022ae4f-242c-4976-af41-24813a431c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
